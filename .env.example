# Video2Docs environment configuration
# Copy this file to .env and adjust values as needed.

# Web UI authentication (defaults for local development)
ADMIN_USER=admin
ADMIN_PASS=admin123

# Flask secret key for sessions (change to a strong random value in production)
SECRET_KEY=change-me

# Output directories (absolute or relative paths).
# On Windows, you can use either forward slashes (output/temp) or double backslashes (output\\temp).
OUTPUT_DIR=output
# TEMP_DIR=output/temp

# Default speech recognition language (BCP-47), e.g., en-US, ru-RU
VIDEO2DOCS_LANGUAGE=en-US

# LLM configuration
# Set a custom Hugging Face model for LLMProcessor (defaults to google/flan-t5-large)
# VIDEO2DOCS_LLM_MODEL=google/flan-t5-large
# VIDEO2DOCS_LLM_MODEL=TinyLlama/TinyLlama-1.1B-Chat-v1.0
# VIDEO2DOCS_LLM_MODEL=microsoft/Phi-3.5-mini-instruct
# VIDEO2DOCS_LLM_MODEL=HuggingFaceTB/SmolLM-135M
# VIDEO2DOCS_LLM_MODEL=TheBloke/Mistral-7B-Instruct-v0.2-GGUF
# VIDEO2DOCS_LLM_MODEL=google/flan-ul2

# Web server settings
HOST=127.0.0.1
PORT=5000
FLASK_DEBUG=0

# Background workers (if applicable)
# MAX_WORKERS=2

# Optional API keys/tokens
# OpenAI API key (used by LangChain/OpenAI integrations)
# OPENAI_API_KEY=
# Hugging Face Hub token (for Inference API / models)
# HUGGINGFACEHUB_API_TOKEN=
